{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticiacaixeta/gsi073/blob/main/GSI073_aula0_regressao_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GSI073 - Tópicos Especiais de Inteligência Artificial\n",
        "\n",
        "## Definição dos dados"
      ],
      "metadata": {
        "id": "Mwsc0ViVertv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZxMYLGefOh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np # Importado para uso com a avaliação no numpy\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X_np = iris.data        # 4 features: sépalas e pétalas\n",
        "# O reshape é necessário para garantir que y_np seja uma matriz de 2D (N, 1)\n",
        "y_np = (iris.target == 1).astype(float).reshape(-1, 1)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 1.1 Separar em treino e teste (80% treino, 20% teste)\n",
        "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(\n",
        "    X_np, y_np, test_size=0.2, random_state=42, stratify=y_np\n",
        ")\n",
        "\n",
        "# 2. Preparar dados para pytorch\n",
        "# Converter os conjuntos separados para tensores do PyTorch\n",
        "X_train = torch.tensor(X_train_np, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train_np, dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test_np, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test_np, dtype=torch.float32)\n",
        "\n",
        "print(f\"Dimensões de Treino (X_train): {X_train.shape}, (y_train): {y_train.shape}\")\n",
        "print(f\"Dimensões de Teste (X_test): {X_test.shape}, (y_test): {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do modelo e treinamento"
      ],
      "metadata": {
        "id": "nUv-LKlIe9Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Definir modelo: regressão logística\n",
        "modelo = torch.nn.Linear(4, 1)  # 4 features → 1 saída (probabilidade de ser Versicolor)\n",
        "\n",
        "# 4. Definir função de perda e algoritmo de otimização\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()  # Combinação de sigmoid + BCE\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "eg97DxIbe0tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução do treinamento"
      ],
      "metadata": {
        "id": "Agjn3aQxfHOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Treino\n",
        "print(\"Iniciando Treinamento...\")\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad() # reseta gradiente senão acumula\n",
        "\n",
        "    # Forward pass usando APENAS dados de treino\n",
        "    outputs = modelo(X_train)\n",
        "    loss = funcao_perda(outputs, y_train)\n",
        "\n",
        "    # Backward pass e otimização\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Treinamento concluído.\")"
      ],
      "metadata": {
        "id": "uuksjyq7e4Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRÁTICA 5: Adicionar uma célula de código para avaliar se o modelo aprendido está bom\n",
        "print(\"\\n--- Avaliação do Modelo no Conjunto de Teste ---\")\n",
        "\n",
        "# Coloca o modelo em modo de avaliação\n",
        "modelo.eval()\n",
        "\n",
        "# Desativa o cálculo de gradientes (economiza recursos na avaliação)\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 1. Fazer predições (logits) no conjunto de TESTE\n",
        "    outputs_test = modelo(X_test)\n",
        "\n",
        "    # 2. Aplicar Sigmoid para obter probabilidades (entre 0 e 1)\n",
        "    probabilities = torch.sigmoid(outputs_test)\n",
        "\n",
        "    # 3. Converter para classes binárias (limite de 0.5)\n",
        "    predictions = (probabilities >= 0.5).float()\n",
        "\n",
        "    # 4. Calcular Acurácia (Accuracy)\n",
        "    correct_predictions = (predictions == y_test).sum().item()\n",
        "    total_predictions = y_test.size(0)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # 5. Calcular a Perda (Loss) no teste\n",
        "    loss_test = funcao_perda(outputs_test, y_test).item()\n",
        "\n",
        "    print(f'Loss no Conjunto de Teste: {loss_test:.4f}')\n",
        "    print(f'Acurácia do Modelo: {accuracy*100:.2f}% ({correct_predictions} de {total_predictions} corretos)')"
      ],
      "metadata": {
        "id": "wWncXiPacXko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRÁTICA 6: Descubra o que tem dentro de nn.Linear\n",
        "print(\"\\n--- Conteúdo de torch.nn.Linear ---\")\n",
        "\n",
        "# A camada torch.nn.Linear implementa a operação fundamental da regressão linear:\n",
        "# Saída = (Entrada * Pesos) + Viés/Bias\n",
        "# Ela contém dois parâmetros (tensores) aprendidos: weight e bias.\n",
        "\n",
        "# 1. Pesos (Weight): A matriz de coeficientes do modelo\n",
        "print(\"1. Pesos (Weight) - Coeficientes (W):\")\n",
        "print(modelo.weight.data)\n",
        "print(f\"Shape: {modelo.weight.data.shape}\")\n",
        "\n",
        "# 2. Bias (Viés): O termo de intercepto (b)\n",
        "print(\"\\n2. Bias (b) - Intercepto:\")\n",
        "print(modelo.bias.data)\n",
        "print(f\"Shape: {modelo.bias.data.shape}\")\n",
        "\n",
        "# O modelo de Regressão Logística é: P(Y=1) = Sigmoid(X * W^T + b)\n",
        "# Os valores acima (W e b) foram otimizados pelo algoritmo SGD."
      ],
      "metadata": {
        "id": "XZPcTGB1cd2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}